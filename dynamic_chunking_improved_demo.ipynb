{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1735b3c7",
   "metadata": {},
   "source": [
    "# üöÄ Dynamic ChunkingHNet - Improved Implementation Demo\n",
    "\n",
    "This notebook demonstrates the improved, production-ready Dynamic ChunkingHNet library with:\n",
    "- ‚úÖ Modular architecture with proper package structure\n",
    "- ‚úÖ Error handling and validation \n",
    "- ‚úÖ Advanced caching system\n",
    "- ‚úÖ Comprehensive testing\n",
    "- ‚úÖ Configuration management\n",
    "- ‚úÖ Logging and monitoring\n",
    "\n",
    "## Key Features\n",
    "1. **Dynamic Boundary Detection**: Uses embedding similarity to detect semantic breaks\n",
    "2. **Adaptive Chunking Pipeline**: Adjusts chunk size based on compression ratio and content\n",
    "3. **Quality Evaluation**: Computes metrics like boundary precision and semantic coherence\n",
    "4. **Interactive Visualizations**: Comprehensive analysis dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106fa4a9-04b2-4ccb-a312-dede5dac6350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc38fd",
   "metadata": {},
   "source": [
    "## 1. Import Improved Modules\n",
    "\n",
    "Let's import the improved Dynamic ChunkingHNet modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import improved Dynamic ChunkingHNet modules\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "try:\n",
    "    from dynamic_chunking_hnet.core.pipeline import DynamicChunkingPipeline\n",
    "    from dynamic_chunking_hnet.core.boundary_detector import SimilarityBasedBoundaryDetector\n",
    "    from dynamic_chunking_hnet.core.routing_module import RoutingModule\n",
    "    from dynamic_chunking_hnet.core.smoothing_module import SmoothingModule\n",
    "    from dynamic_chunking_hnet.evaluation.metrics import ChunkingQualityMetrics\n",
    "    from dynamic_chunking_hnet.utils.config import load_config\n",
    "    from dynamic_chunking_hnet.utils.monitoring import get_logger, performance_monitor\n",
    "    from dynamic_chunking_hnet.utils.cache import CacheManager\n",
    "    print(\"‚úÖ Successfully imported improved Dynamic ChunkingHNet modules!\")\n",
    "    MODULES_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Could not import improved modules: {e}\")\n",
    "    print(\"Please ensure the package is properly installed.\")\n",
    "    MODULES_AVAILABLE = False\n",
    "\n",
    "# Setup visualization\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"\\nModules available: {MODULES_AVAILABLE}\")\n",
    "if MODULES_AVAILABLE:\n",
    "    print(\"üéâ Ready to demonstrate improved Dynamic ChunkingHNet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee0982",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Setup Monitoring\n",
    "\n",
    "Demonstrate the improved configuration management and monitoring capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODULES_AVAILABLE:\n",
    "    # Load configuration\n",
    "    try:\n",
    "        config = load_config('config/default.yaml')\n",
    "        print(\"‚úÖ Configuration loaded successfully!\")\n",
    "        print(f\"Default compression ratio: {config.get('compression_ratio', 'Not set')}\")\n",
    "        print(f\"Cache enabled: {config.get('cache', {}).get('enabled', 'Not set')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Using default configuration: {e}\")\n",
    "        config = {'compression_ratio': 6.0}\n",
    "    \n",
    "    # Setup logging\n",
    "    logger = get_logger('demo')\n",
    "    logger.info(\"Starting Dynamic ChunkingHNet demonstration\")\n",
    "    \n",
    "    # Initialize performance monitoring\n",
    "    print(\"‚úÖ Monitoring and logging initialized\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed without modules. Please install the package first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f06e8ac",
   "metadata": {},
   "source": [
    "## 3. Basic Usage with Improved Pipeline\n",
    "\n",
    "Demonstrate the basic usage of the improved Dynamic ChunkingHNet pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8957c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODULES_AVAILABLE:\n",
    "    # Sample text for demonstration\n",
    "    sample_text = \"\"\"\n",
    "    Machine learning is transforming how we process information. \n",
    "    Neural networks can learn complex patterns from data. \n",
    "    Natural language processing enables computers to understand text. \n",
    "    The H-Net architecture introduces dynamic chunking mechanisms. \n",
    "    This approach outperforms traditional fixed-size tokenization methods.\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    print(\"üìù Sample Text:\")\n",
    "    print(f\"{sample_text}\\n\")\n",
    "    print(f\"Text length: {len(sample_text.split())} tokens\")\n",
    "    \n",
    "    # Initialize pipeline with monitoring\n",
    "    @performance_monitor('pipeline_processing')\n",
    "    def process_with_monitoring(text: str, compression_ratio: float = 6.0):\n",
    "        pipeline = DynamicChunkingPipeline(compression_ratio=compression_ratio)\n",
    "        return pipeline.process_text(text, return_metrics=True)\n",
    "    \n",
    "    # Process the text\n",
    "    print(\"üîÑ Processing text with improved pipeline...\")\n",
    "    result = process_with_monitoring(sample_text)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìä Results:\")\n",
    "    print(f\"Original tokens: {result['num_tokens']}\")\n",
    "    print(f\"Chunks created: {result['num_chunks']}\")\n",
    "    print(f\"Compression ratio achieved: {result['compression_ratio_achieved']:.2f}\")\n",
    "    \n",
    "    print(\"\\nüìù Generated Chunks:\")\n",
    "    for i, chunk in enumerate(result['chunks'], 1):\n",
    "        chunk_text = ' '.join(chunk)\n",
    "        print(f\"  {i}: {chunk_text}\")\n",
    "    \n",
    "    logger.info(\"Basic processing completed\", \n",
    "                chunks=result['num_chunks'], \n",
    "                compression=result['compression_ratio_achieved'])\n",
    "else:\n",
    "    print(\"‚ùå Modules not available for demonstration.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dynamic ChunkingHNet (venv)",
   "language": "python",
   "name": "dynamic_chunking_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
